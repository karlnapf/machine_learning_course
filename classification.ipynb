{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Short course introduction to Machine Learning: Classification\n",
    "### March 14, 2017\n",
    "\n",
    "Prepared by [Heiko Strathmann](http://www.herrstrathmann.de/). Loosely based on previous versions by: Dino Sejdinovic, John Shawe-Taylor, Tom Diethe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract\n",
    "Using a series of examples, in this exercise session you will familiarise yourselves with the naive Bayes classifier and support vector machines.\n",
    "This is an interactive IPython notebook.\n",
    "It runs on a remote server to which you connect via the web-browser.\n",
    "The original version of the notebook is available [here](https://github.com/karlnapf/machine_learning_course).\n",
    "\n",
    "NOTE: The notebook makes use of the Shogun Machine Learning Toolbox, http://shogun.ml. If you want to run it locally you need to install Shogun.\n",
    "You could also run it in the Shogun cloud at http://cloud.shogun.ml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing necessary libraries\n",
    "We here use [numpy](http://www.numpy.org/), [matplotlib](http://matplotlib.org/) and [Shogun](http://shogun.ml).\n",
    "Make sure to check the documentation available online.\n",
    "If you are coming from Matlab, [this](https://docs.scipy.org/doc/numpy-dev/user/numpy-for-matlab-users.html) might be helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import modshogun as sg\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes classifier\n",
    "\n",
    "Assume that we have training examples $S=\\left\\{ (\\mathbf{x}^{(i)},y^{(i)})\\right\\} _{i=1}^{m}$,\n",
    "where each $\\mathbf{x}^{i}=\\left(x_{1}^{(i)},\\ldots,x_{D}^{(i)}\\right)$\n",
    "is a $D$-dimensional vector and $y^{(i)}$ is the corresponding label.\n",
    "For a new data point $\\mathbf{x}_{tst}$, we wish to predict its label\n",
    "$y_{tst}$ using the Bayes theorem:\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "y_{tst} & = & \\arg\\max_{y}P(y|\\mathbf{x}_{tst})\\\\\n",
    " & = & \\arg\\max_{y}\\frac{P(\\mathbf{x}_{tst}|y)P(y)}{P(\\mathbf{x}_{tst})}\\\\\n",
    " & = & \\arg\\max_{y}P(\\mathbf{x}_{tst}|y)P(y),\n",
    "\\end{eqnarray*}\n",
    "since denominator does not depend on $y$. However, this requires\n",
    "estimation of a high-dimensional probability distribution $P(\\mathbf{x}|y)$,\n",
    "which is impossible in most interesting cases. Naive Bayes makes a\n",
    "strong (\\emph{naive}) independence assumption on this probability\n",
    "distribution, i.e., that\n",
    "\\begin{eqnarray*}\n",
    "P(\\mathbf{x}|y) & = & \\prod_{j=1}^{D}P(x_{j}|y),\n",
    "\\end{eqnarray*}\n",
    "i.e., individual components of $\\mathbf{x}$ are conditionally independent\n",
    "given its label $y$. Classifier then proceeds by estimating $D$\n",
    "one dimensional distributions $P(x_{j}|y)$, which is a much easier\n",
    "task. For example, when variables $x_{j}$ are binary, estimation\n",
    "of $P(x_{j}|y)$, can be expressed through:\n",
    "\\begin{eqnarray*}\n",
    "p_{jk} & = & P(x_{j}=1|y=k),\\quad\\pi_{k}=P(y=k),\n",
    "\\end{eqnarray*}\n",
    "with maximum likelihood (ML) estimates given by:\n",
    "\\begin{eqnarray}\n",
    "\\hat{p}_{jk} & = & \\frac{\\#\\left\\{ (\\mathbf{x},y)\\in S\\,:\\;x_{j}=1,y=k\\right\\} }{\\sum_{l=1}^{D}\\#\\left\\{ (\\mathbf{x},y)\\in S\\,:\\;x_{l}=1,y=k\\right\\} },\\\\\n",
    "\\hat{\\pi}_{k} & = & \\frac{\\#\\left\\{ (\\mathbf{x},y)\\in S\\,:\\;y=k\\right\\} }{m}.\n",
    "\\end{eqnarray}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a real-world dataset of text extracted from Yahoo! pages which has been used in previous studies, \n",
    "\n",
    "`A. Vinokourov, D. R. Hardoon and J. Shawe-Taylor (2003), Learning the Semantics of Multimedia Content with Application to Web Image Retrieval and Classification. 4th International Symposium on Independent Component Analysis (ICA 2003), Nara, Japan.`\n",
    "\n",
    "and\n",
    "\n",
    "`T. Joachims (2002). Learning to Classify Text Using Support Vector Machines.`\n",
    "\n",
    "We will construct a classifier that predicts whether a given document belongs to 'Sport' or 'Aviation' category.\n",
    "As working with text itself is unwieldy, each document is represented by a $D$-dimensional vector encoding the number of times that each of the $D$ words in the dictionary (the union of all words occurring in any of the texts) occurs in that document - the so called 'bag of words' representation (this is clearly a very crude representation\n",
    "since it does not take into account the order of the words).\n",
    "This leads to a notion of similarity (kernel) between two text documents, as an inner product between these 'bag of words' representations, given by:\n",
    "\\begin{eqnarray*}\n",
    " &  & k(\\texttt{text 1},\\texttt{text 2})=\n",
    " &  & \\sum_{{\\texttt{word}}\\ \\in\\ {\\texttt{dictionary}}}(\\#{\\texttt{occ. of word} \\in \\texttt{text 1}})\\times(\\#{\\texttt{occ. of word} \\in \\texttt{text 2}}).\n",
    "\\end{eqnarray*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The dataset\n",
    "\n",
    "We begin by loading the the two sets of documents and exploring their size and content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"docs_sport.txt\", 'r') as f:\n",
    "    docs_sport = f.readlines()\n",
    "\n",
    "with open(\"docs_aviation.txt\", 'r') as f:\n",
    "    docs_aviation = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print type(docs_sport), len(docs_sport)\n",
    "print type(docs_aviation), len(docs_sport)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print docs_sport[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print docs_aviation[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now write a function that 'stacks' the two sets of documents on top of each other, forming the $x$ of the dataset.\n",
    "We will use this function throughout the exercise.\n",
    "In order to classify the documents, we need to generate a vector of labels $y$ for them.\n",
    "This is simply a vector $y$ of which each component corresponds to exactly one document.\n",
    "We here set them to be either $+1$ or $-1$, based on which document class it corresponds to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def concat_two_class_data(Xs, Ys):\n",
    "    \"\"\"\n",
    "    Turns a set of Xs and Ys into a classification problem X with binarly labels y.\n",
    "    \"\"\"\n",
    "    \n",
    "    assert type(Xs) == type(Ys)\n",
    "    \n",
    "    if type(Xs) == np.ndarray:\n",
    "        # deal with plain vectors and matrices\n",
    "        if Xs.ndim==2 and Ys.ndim==2:\n",
    "            X = np.vstack([Xs, Ys])\n",
    "        elif Xs.ndim==1 and Ys.ndim==1:\n",
    "            X = np.hstack([Xs, Ys])\n",
    "    elif type(Xs) == list:\n",
    "        # lists can be appended\n",
    "        X = Xs + Ys\n",
    "    else:\n",
    "        raise TypeError(\"Unknown data type\")\n",
    "        \n",
    "    y = np.zeros(len(X))\n",
    "    y[:len(Xs)]=1.\n",
    "    y[len(Xs):]=-1.\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "docs, y = concat_two_class_data(docs_sport, docs_aviation)\n",
    "print len(docs)\n",
    "print y.shape\n",
    "print np.unique(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now turn the documents into a the bag-of-words representation mentioned above.\n",
    "For that, we first generate a single big string in which we concatenate all documents, using [join](https://www.tutorialspoint.com/python/string_join.htm). We then [split](https://www.tutorialspoint.com/python/string_split.htm) this big string into individual words, each of which we [strip](https://www.tutorialspoint.com/python/string_strip.htm) to remove any spaces at beginning or end.\n",
    "Finally, we extract a list of unique words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "joined_docs = \" \".join(docs)\n",
    "all_words = joined_docs.split(\" \")\n",
    "all_words = [word.strip(\" \") for word in all_words]\n",
    "all_words = np.unique(all_words)\n",
    "print all_words[2350:2360]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to turn a document into a feature vector, we now simply for each document need to [count](https://www.tutorialspoint.com/python/string_count.htm) for each word how many times it appears in the doc.\n",
    "This produces a binary vector whose length is equal to the number of unique words in all documents.\n",
    "Note that we normalise by the document length to avoid larger documents to be over-weighted.\n",
    "Also note: this will take a moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = np.zeros((len(docs), len(all_words)))\n",
    "for i,doc in enumerate(docs):\n",
    "    X[i] = np.array([doc.count(w) for w in all_words], dtype=np.float64)\n",
    "    X[i] /= len(doc.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print X.shape\n",
    "print X[0]\n",
    "print np.sum(X[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next wish to randomly split the data into training and testing parts. For that, we write another function that we will re-use later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_train_test(X, y, train_ratio = 0.1):\n",
    "    \"\"\"\n",
    "    Takes 2d array X and 1d array y and (randomly) splits into train and test parts, based on the provided ratio.\n",
    "    \"\"\"\n",
    "    assert len(X) == len(y)\n",
    "    assert train_ratio>0 and train_ratio <1\n",
    "    \n",
    "    num_train = np.int(np.round(len(X))*train_ratio)\n",
    "    inds = np.random.permutation(len(X))\n",
    "\n",
    "    inds_train = inds[:num_train]\n",
    "    inds_test = inds[num_train:]\n",
    "    \n",
    "    X_train = X[inds_train]\n",
    "    y_train = y[inds_train]\n",
    "    X_test = X[inds_test]\n",
    "    y_test = y[inds_test]\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = split_train_test(X,y,train_ratio=0.125)\n",
    "\n",
    "print X_train.shape\n",
    "print X_test.shape\n",
    "print y_train.shape\n",
    "print y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running naive Bayes\n",
    "\n",
    "We are now ready to apply the naive Bayes classifier to predict the class label of the test documents.\n",
    "As the naive Bayes classifier for binary vectors is extremely simple, we can just implement it in a few lines.\n",
    "We provide you with a Python implementation of it.\n",
    "Try to read the below code and understand how it connects to the Math description above.\n",
    "It is no problem if you don't understand all the details for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def naive_bayes_binary(X_train,y_train, X_test):\n",
    "    classes = np.unique(y_train)\n",
    "    num_classes = len(classes)\n",
    "    D = X_train.shape[1]\n",
    "    m = X_train.shape[0]\n",
    "    \n",
    "    pie = np.array([np.float64(np.sum(y==k))/m for k in classes])\n",
    "    \n",
    "    p = np.zeros((D, num_classes))\n",
    "    log_posterior_test = np.zeros((len(X_test), num_classes))\n",
    "    for k,c in enumerate(classes):\n",
    "        all_docs_class_c = X_train[y==c]\n",
    "        num_occurences_of_each_feature = np.sum(all_docs_class_c, axis=0)+1\n",
    "        num_occurences = np.sum(all_docs_class_c)\n",
    "        p[:,k] = num_occurences_of_each_feature / num_occurences\n",
    "\n",
    "        log_posterior_test[:,k] = np.dot(X_test,np.log(p[:,k])) + np.log(pie[k]);\n",
    "\n",
    "    return np.argmax(log_posterior_test, axis=1)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We run the naive Bayes classifer and predict the labels of the test data. We can then compute the number of mismatches of the 'true' test labels and the predicted test labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = naive_bayes_binary(X,y, X_test)\n",
    "\n",
    "print \"Predictions\", y_pred[:16]\n",
    "print \"True labels\", y_test[:16]\n",
    "\n",
    "y_pred_binary = y_pred*2-1\n",
    "print \"Test accuracy is %.2f\" % np.mean(y_pred_binary == y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks\n",
    "\n",
    " * Check how many documents in each of the classes were misclassified\n",
    " * Look at the misclassified documents\n",
    " * Experiment with different sizes of splits of training and test data, and mark how performance depends on the size of the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Naive Bayes is one of the simplest density estimation methods from which we can form one of the standard classification methods in machine learning.\n",
    "Its fame is partly due to the following properties: \n",
    "\n",
    " * Very easy to program and intuitive \n",
    " * Fast to train and to use as a classifier \n",
    " * Very easy to deal with missing attributes (we did not do that here)\n",
    " * Very popular in fields such as computational linguistics/NLP \n",
    "\n",
    "As we have seen, naive Bayes can be useful in classification of text documents.\n",
    "The reason that naive Bayes may be able to classify documents reasonably well in this way is that the conditional independence assumption is not so silly:\n",
    "if we know people are talking about politics, this\n",
    "perhaps is almost sufficient information to specify what kinds of other words they will be using - we don't need to know anything else (of course, if you want ultimately a more powerful text classifier, you need to relax this assumption)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing to SVM\n",
    "\n",
    "The above accuracy is already quite good. However, the naive Bayes classifier makes some extremely simplifying assumptions about the data. We will develop more intuition on this later. For now, let's see how the mighty support vector machine (SVM) performs on this task. We use an implementation of the open-source [Shogun Machine Learning Toolbox](http://shogun.ml) here as the SVM is not so staight-forward to implement (efficienctly)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use Shogun, we need to pass the data objects to it.\n",
    "For that, we define another helper function. This does simply copy our training objects to Shogun.\n",
    "In this notebook, we will use the a prefix `sg_` for all projects that are owned by Shogun, e.g. `sg_y_train` is the Shogun representation of y_train.\n",
    "\n",
    "\n",
    "If you are interested, have a look at the [API](http://shogun.ml/api) of the classes: `DenseFeatures`, `BinaryLabels`, `MulticlassLabels`, `LibSVM`, `LinearKernel`, `GaussianKernel`, `CrossValidation` and check out usage [examples](http://shogun.ml/examples).\n",
    "At http://shogun.ml/showroom, you can also find notebooks for classification, regression, support vector machines, and model-selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pass_to_shogun(X_train, X_test, y_train, y_test, multiclass_labels=False):\n",
    "    \"\"\"\n",
    "    Converts the given objects into Shogun representation\n",
    "    \"\"\"\n",
    "    sg_X_train = sg.RealFeatures(X_train.T)\n",
    "    sg_X_test = sg.RealFeatures(X_test.T)\n",
    "    if multiclass_labels:\n",
    "        sg_y_train = sg.MulticlassLabels((y_train+1)/2.)\n",
    "        sg_y_test = sg.MulticlassLabels((y_test+1)/2.)\n",
    "    else:\n",
    "        sg_y_train = sg.BinaryLabels(y_train)\n",
    "        sg_y_test = sg.BinaryLabels(y_test)\n",
    "\n",
    "    return sg_X_train, sg_X_test, sg_y_train, sg_y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sg_X_train, sg_X_test, sg_y_train, sg_y_test = pass_to_shogun(X_train, X_test, y_train, y_test)\n",
    "\n",
    "C = 50.0\n",
    "sg_svm = sg.LibSVM(C, sg.LinearKernel(), sg_y_train)\n",
    "sg_svm.train(sg_X_train);\n",
    "\n",
    "sg_y_pred = sg_svm.apply(sg_X_test)\n",
    "y_pred = sg_y_pred.get_labels()\n",
    "\n",
    "print \"Test accuracy is %.2f\" % np.mean(y_pred == y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a much better result than the naive Bayes classifier. Note that accuracy sometimes is not a good measure of performance. especially for non-symmetric class label ratios. With Shogun, it is easy to use other measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print sg.AccuracyMeasure().evaluate(sg_y_pred, sg_y_test)\n",
    "print sg.ROCEvaluation().evaluate(sg_y_pred, sg_y_test)\n",
    "print sg.F1Measure().evaluate(sg_y_pred, sg_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When Naive Bayes fails\n",
    "\n",
    "We will now explore the independence assumption that naive Bayes makes in more detail.\n",
    "For that, we will consider a continuous case (previously our data was binary vectors, now they are real-valued vectors).\n",
    "\n",
    "We provide you with a helper function that generates two blos of 2D [normal distributed](https://en.wikipedia.org/wiki/Multivariate_normal_distribution) data.\n",
    "Try to understand the function, but do not worry if you don't -- we will plot it below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_elongated_gaussians(n_x=400, n_y=400,\n",
    "                            mu_x=np.array([1, -1.0]), mu_y=np.array([-1, 1.0]),\n",
    "                            inv_eig_vals=np.array([2,0.01]), noise_dim=0):\n",
    "\n",
    "    n_x=400;\n",
    "    n_y=400;\n",
    "\n",
    "    # covariance defined below via eigendecomposition C=U*S*U'\n",
    "\n",
    "    # U controls the eigenvectors of the covariance matrix\n",
    "    theta=-np.pi/4;\n",
    "    U   =  np.array([[np.cos(theta), -np.sin(theta)], [np.sin(theta),  np.cos(theta)]])\n",
    "    s_inv = np.array(inv_eig_vals)          \n",
    "    Sigma = np.dot(U, np.diag(1.0/s_inv)).dot(U.T)\n",
    "\n",
    "    # sample from multivariate Gaussian with covariance Sigma\n",
    "    L = np.linalg.cholesky(Sigma)\n",
    "    Xs =  L.dot(np.random.randn(2, n_x)).T + mu_x\n",
    "    Ys =  L.dot(np.random.randn(2, n_y)).T + mu_y\n",
    "\n",
    "    # add noise_dim dimensions of \"noise\" \n",
    "    # increase to make the problem harder\n",
    "    if noise_dim>0:\n",
    "        Xs = np.hstack([Xs, np.random.randn(n_x, noise_dim)])\n",
    "        Ys = np.hstack([Ys, np.random.randn(n_y, noise_dim)])\n",
    "        \n",
    "    return Xs, Ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_two_class_data(Xs, Ys, item_strings=[\"Xs\", \"Ys\"]):\n",
    "    plt.plot(Xs[:,0], Xs[:,1], 'r.')\n",
    "    plt.plot(Ys[:,0], Ys[:,1], 'b.')\n",
    "    plt.legend(item_strings)\n",
    "    plt.grid(True)\n",
    "    plt.xlabel(item_strings[0])\n",
    "    plt.ylabel(item_strings[1])\n",
    "    plt.axes().set_aspect('equal', 'datalim')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin with generating dataset where Gaussian naive Bayes works well, i.e. where the 'independence of the components' assumption holds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xs, Ys = gen_elongated_gaussians(inv_eig_vals=[1., 1.])\n",
    "plot_two_class_data(Xs, Ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the Gaussian version of naive Bayes is slightly more involved to program, we use Shogun here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X,y = concat_two_class_data(Xs, Ys)\n",
    "X_train, X_test, y_train, y_test = split_train_test(X,y,train_ratio=0.125)\n",
    "sg_X_train, sg_X_test, sg_y_train, sg_y_test = pass_to_shogun(X_train, X_test, y_train, y_test, multiclass_labels=True)\n",
    "\n",
    "sg_gnb = sg.GaussianNaiveBayes()\n",
    "sg_gnb.set_features(sg_X_train)\n",
    "sg_gnb.set_labels(sg_y_train)\n",
    "\n",
    "sg_gnb.train();\n",
    "\n",
    "sg_y_pred = sg_gnb.apply(sg_X_test)\n",
    "\n",
    "print \"Test accuracy:\", sg.MulticlassAccuracy().evaluate(sg_y_pred, sg_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This results looks good.\n",
    "Here is a function that plots how the predictions on test data look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_two_class_predictions(X_test, y_pred, item_strings=[\"Xs\", \"Ys\"]):\n",
    "    y_values = np.unique(y_pred)\n",
    "    \n",
    "    X_pos = X_test[y_pred==y_values[0]]\n",
    "    \n",
    "    if len(y_values)>1:\n",
    "        X_neg = X_test[y_pred==y_values[1]]\n",
    "    \n",
    "    plt.plot(X_pos[:,0],X_pos[:,1], 'b.')\n",
    "    if len(y_values)>1:\n",
    "        plt.plot(X_neg[:,0],X_neg[:,1], 'r.')\n",
    "    plt.legend([\"Predicted %s\" % item_strings[0], \"Predicted %s\" % item_strings[1]])\n",
    "    plt.grid(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_two_class_predictions(X_test, sg_y_pred.get_values()*2-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you see, Gaussian naive Bayes seems to do well on this problem.\n",
    "This comes from the fact that the two dimensions of the data are indeed independent (i.e. have 'round' point clouds). \n",
    "\n",
    "Next, we look at a case where there is correlation in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xs, Ys = gen_elongated_gaussians()\n",
    "\n",
    "plot_two_class_data(Xs, Ys)\n",
    "\n",
    "X,y = concat_two_class_data(Xs, Ys)\n",
    "X_train, X_test, y_train, y_test = split_train_test(X,y,train_ratio=0.125)\n",
    "\n",
    "sg_X_train, sg_X_test, sg_y_train, sg_y_test = pass_to_shogun(X_train, X_test, y_train, y_test, multiclass_labels=True)\n",
    "\n",
    "sg_gnb = sg.GaussianNaiveBayes()\n",
    "sg_gnb.set_features(sg_X_train)\n",
    "sg_gnb.set_labels(sg_y_train)\n",
    "\n",
    "sg_gnb.train();\n",
    "\n",
    "sg_y_pred = sg_gnb.apply(sg_X_test)\n",
    "y_pred = sg_y_pred.get_labels()\n",
    "\n",
    "plt.figure()\n",
    "plot_two_class_predictions(X_test, y_pred)\n",
    "print \"Test accuracy:\", sg.MulticlassAccuracy().evaluate(sg_y_pred, sg_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, Gaussian naive Bayes completely fails on this example.\n",
    "Re-run it a few times to see how the algorithm tries to predict 'round' point clounds in the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task\n",
    "\n",
    " * Discuss the independence assumption with the people around you (neighbour, TA), and make sure you get the intuition.\n",
    " * Run a SVM on the same dataset, taking inspiration from the the case above. You should get almost perfect accuracy (>95%)\n",
    " * Have a look at the function `plot_support_vectors` below.\n",
    " Pass the trained svm, and `x_range=[-30,30], y_range=[-30,30]`.\n",
    " It will show you the support vectors that span the solution, and a heatmap of the 'distance from the separating hyper-plane'.\n",
    " What can you see? Discuss this with your neighbour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run SVM on the correlated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_support_vectors(sg_svm,X_train,y_train,x_range, y_range):\n",
    "    res = 100\n",
    "    x = np.linspace(x_range[0], x_range[1], res)\n",
    "    y = np.linspace(y_range[0], y_range[1], res)\n",
    "\n",
    "    xx, yy=np.meshgrid(x, y)\n",
    "    grid=np.array((np.ravel(xx), np.ravel(yy)))\n",
    "    sg_out=sg_svm.apply(sg.RealFeatures(grid))\n",
    "    z=sg_out.get_values().reshape((res, res))\n",
    "\n",
    "    plt.jet()\n",
    "    plt.figure(figsize=(16,6))\n",
    "    plt.subplot(121)\n",
    "    plt.pcolor(x, y, z)\n",
    "    plt.contour(x , y, z, linewidths=1, colors='black', hold=True)\n",
    "    plt.scatter(X_train[:,0],X_train[:,1], c=y_train)\n",
    "    plt.title(\"Training data\")\n",
    "\n",
    "    sv = sg_svm.get_support_vectors()\n",
    "    plt.subplot(122)\n",
    "    plt.jet()\n",
    "    c=plt.pcolor(x, y, z)\n",
    "    plt.contour(x , y, z, linewidths=1, colors='black', hold=True)\n",
    "    plt.colorbar(c)\n",
    "    plt.scatter(X_train[sv,0],X_train[sv,1], c=y_train[sv])\n",
    "    plt.title(\"Support vectors\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot the support vectors\n",
    "# plot_support_vectors(sg_svm,X_train,y_train,x_range=[-30,30], y_range=[-30,30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non linearly-separable data\n",
    "\n",
    "We now consider a simple synthetic data which illustrates the\n",
    "strength of non-linear kernels.\n",
    "\n",
    "For that, we use the above Gaussian data script to generate 2D data, where positive examples are a mixture of bivariate gaussians with means $(-1,-1)$ and $(1,1)$ while the negative examples are a mixture of bivariate gaussians with means $(-1,1)$ and $(1,-1)$.\n",
    "All Gaussian components have the same covariance matrix.\n",
    "\n",
    "## Task\n",
    " * What is the best line that separates the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xs, Ys = gen_elongated_gaussians(mu_x=np.array([-1, -1.0]), mu_y=np.array([-1, 1.0]), inv_eig_vals=np.array([4,2]))\n",
    "Xs_, Ys_ = gen_elongated_gaussians(mu_x=np.array([1, 1.0]), mu_y=np.array([1, -1.0]), inv_eig_vals=np.array([4,2]))\n",
    "\n",
    "Xs = np.vstack([Xs, Xs_])\n",
    "Ys = np.vstack([Ys, Ys_])\n",
    "plot_two_class_data(Xs, Ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does the SVM work well on this example?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X,y = concat_two_class_data(Xs, Ys)\n",
    "X_train, X_test, y_train, y_test = split_train_test(X,y,train_ratio=0.125)\n",
    "sg_X_train, sg_X_test, sg_y_train, sg_y_test = pass_to_shogun(X_train, X_test, y_train, y_test)\n",
    "\n",
    "sg_svm = sg.LibSVM(C, sg.LinearKernel(), sg_y_train)\n",
    "sg_svm.train(sg_X_train);\n",
    "sg_svm.train();\n",
    "\n",
    "sg_y_pred = sg_svm.apply(sg_X_test)\n",
    "plot_two_class_predictions(X_test, sg_y_pred.get_labels())\n",
    "print \"Test accuracy:\", sg.AccuracyMeasure().evaluate(sg_y_pred, sg_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can re-run the above code a few times.\n",
    "You will see that the predicted labels are always separated by a line.\n",
    "Since there is no line that separates the training data, we get poor accuracy.\n",
    "\n",
    "To address this problem, we now run SVM with a Gaussian rbf kernel $$k(x,x')=\\exp(-\\sigma\\left\\Vert x-x'\\right\\Vert _{2}^{2})$$\n",
    "with parameters $\\sigma=1$.\n",
    "\n",
    "A SVM with\n",
    "a gaussian kernel first maps the data from $\\mathbb{R}^{2}$ into a higher dimensional feature space, where the resulting 'features' can be linearly separated, and a maximum-margin hyperplane is fitted in this space.\n",
    "When mapped back to our original space, the classifier is non-linear.\n",
    "To get some intuition of how this works, you can have a look [here](http://www.youtube.com/watch?v=3liCbRZPrZA), where a polynomial kernel with a three-dimensional feature space is used.\n",
    "In general, feature space can have a large and even an infinite number of dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sigma = 1.\n",
    "sg_kernel = sg.GaussianKernel()\n",
    "sg_kernel.set_width(sigma)\n",
    "\n",
    "C=1.\n",
    "sg_svm = sg.LibSVM(C, sg_kernel, sg_y_train)\n",
    "sg_svm.train(sg_X_train);\n",
    "\n",
    "sg_y_pred = sg_svm.apply(sg_X_test)\n",
    "plot_two_class_predictions(X_test, sg_y_pred.get_labels())\n",
    "print \"Test accuracy:\", sg.AccuracyMeasure().evaluate(sg_y_pred, sg_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the prediction are now much better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task\n",
    "\n",
    " * Experiment with different values of sigma, ranging from very small ($\\sigma=2^{-8}$) to very large ($\\sigma=2^{8}$). How does the choice affect the test accuracy?\n",
    " * Plot the predicted labels for the **training data** for very small $\\sigma$. What can you see? \n",
    " * Read on [overfitting](https://en.wikipedia.org/wiki/Overfitting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter choice and cross-validation\n",
    "\n",
    "Let us now do a systematic search for the kernel width $\\sigma$.\n",
    "For that, we generate a sequence of widths to try,  train the SVM on each of them, and monitor performance.\n",
    "In theory, we then can choose the parameter that worked best.\n",
    "Note that the test set is typically unavailable for parameter training (you might not even have seen it when you are building your prediction model).\n",
    "So let's just use the training data to measure performance.\n",
    "\n",
    "## Task\n",
    " * Fill in the loop in the code below to:\n",
    "  * set the kernel to the current `width`\n",
    "  * train the svm\n",
    "  * store the test accuracy in `results[i]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "widths = 2**np.linspace(-10, 10, 20)\n",
    "\n",
    "results = np.zeros(len(widths))\n",
    "for i,width in enumerate(widths):\n",
    "    # TASK: fill in the loop\n",
    "    pass # <- delete this\n",
    "\n",
    "plt.plot(np.log2(widths), results, 'b-')\n",
    "plt.xlabel(r\"$\\log_2 (\\sigma)$\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.grid(True)\n",
    "\n",
    "plt.plot(np.log2(widths[np.argmax(results)]), np.max(results), 'r*', markersize=15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you did everything right, there should be a plot.\n",
    "From the plot it seems like we can get almost perfect performance by choosing a very small $\\sigma$.\n",
    "That seems great, let's train the SVM with the best $\\sigma$.\n",
    "Now that we have trained the model, we can imagine somebody gives us test data, and we apply our almost perfect SVM to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_width = widths[np.argmax(results)]\n",
    "sg_kernel.set_width(best_width)\n",
    "sg_svm.train()\n",
    "sg_y_pred = sg_svm.apply(sg_X_test)\n",
    "\n",
    "\n",
    "plot_two_class_predictions(X_test, sg_y_pred.get_labels())\n",
    "print \"Test accuracy of best width of %.2f is %.2f\" % (best_width, sg.AccuracyMeasure().evaluate(sg_y_pred, sg_y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task\n",
    "\n",
    " * What happened? Training accuracy was almost 100%, but test accuracy is almost as bad as it can get: 50%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two extremely important aspects of machine learning are:\n",
    "\n",
    " * Never ever tune the parameters of your algorithm on training data -- you will overfit. \n",
    " * If you use test data to tune parameters of your algoritm, it is **not** test data anymore. If you want to report test performance, you need to get more data.\n",
    " \n",
    "With that in mind, we now use cross-validation to tune the parameters.\n",
    "Below, we show you how to compute the cross-validation accuracy.\n",
    "This quantify behaves similar to the test accuracy, but you compute it from only looking at the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_folds = 5\n",
    "sg_split = sg.StratifiedCrossValidationSplitting(sg_y_train, num_folds)\n",
    "sg_xval = sg.CrossValidation(sg_svm, sg_X_train, sg_y_train,\n",
    "                          sg_split, sg.AccuracyMeasure())\n",
    "\n",
    "sg_xval.set_num_runs(5)\n",
    "sg_xval.get_global_parallel().set_num_threads(2)\n",
    "\n",
    "sigma = 2**-10\n",
    "sg_kernel.set_width(sigma)\n",
    "print \"X-validation accuracy for sigma=%.2f is %.2f\" % (sigma, sg.CrossValidationResult.obtain_from_generic(sg_xval.evaluate()).mean)\n",
    "\n",
    "sigma = 1\n",
    "sg_kernel.set_width(sigma)\n",
    "print \"X-validation accuracy for sigma=%.2f is %.2f\" % (sigma, sg.CrossValidationResult.obtain_from_generic(sg_xval.evaluate()).mean)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, cross-validation is able to detect bad parameters (the ones that give you high training accuracy but low test accuracy.\n",
    "\n",
    "Here is how it works:\n",
    " * It divides the training set in $k$ disjoint sets.\n",
    " * Each of these $k$ sets of samples is once lifted out as the validation set, and the remaining $k-1$ sets are used for training.\n",
    " * As a result, we get $k$ validation scores.  The average of these scores is used as a good estimate of the test set performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task\n",
    "\n",
    " * Can you implement cross-validation yourself? Have a look at the function `split_train_test` from above on how to split data.\n",
    " * Hint: you could actually start by using the `split_train_test` directly.\n",
    " The subsets would not be disjoint in this case, but you should still be able to get a good estimate of the test accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we use cross-validation to find the $\\sigma$ that leads to the best accuracy.\n",
    "We here also keep track of the standard deviation over $k$ cross-validation folds to get a feeling for how certain we are about the accuracy estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = np.zeros(len(widths))\n",
    "results_std = np.zeros(len(widths))\n",
    "for i,width in enumerate(widths):\n",
    "    sg_kernel.set_width(width)\n",
    "    sg_result = sg_xval.evaluate()\n",
    "    sg_result = sg.CrossValidationResult.obtain_from_generic(sg_result)\n",
    "    results[i]=sg_result.mean\n",
    "    results_std[i]=sg_result.std_dev\n",
    "\n",
    "best_width = widths[np.argmax(results)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(np.log2(widths), results, 'b-')\n",
    "plt.plot(np.log2(widths), results-2*results_std, 'b--')\n",
    "plt.plot(np.log2(widths), results+2*results_std, 'b--')\n",
    "plt.xlabel(r\"$\\log_2 (\\sigma)$\")\n",
    "plt.ylabel(\"X-validation accuracy\")\n",
    "plt.grid(True)\n",
    "\n",
    "plt.plot(np.log2(widths[np.argmax(results)]), np.max(results), 'r*', markersize=15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the found kernel bandwidth and check the test performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sg_kernel.set_width(best_width)\n",
    "sg_svm.train(sg_X_train);\n",
    "\n",
    "sg_y_pred = sg_svm.apply(sg_X_test)\n",
    "plot_two_class_predictions(X_test, sg_y_pred.get_labels())\n",
    "print \"Test accuracy:\", sg.AccuracyMeasure().evaluate(sg_y_pred, sg_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the cross-validation estimate is still over-estimating the performance slightly: the test performance is a bit lower.\n",
    "This is very common and reminds us that we should never report cross-validation accuracy as test performance (i.e. we used the testing data for tuning parameters) -- it will most likely be less on a **real** test set.\n",
    "\n",
    "Finally, let's have a look atht the support vectors of the final model.\n",
    "As you can see, only the datapoints close to the decision boundary are part of the SVM model.\n",
    "This makes the SVM very efficient to apply, as only few of the original datapoints need to be touched to predict the class of a test point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_support_vectors(sg_svm,X_train,y_train,x_range=[-4,4], y_range=[-4,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
